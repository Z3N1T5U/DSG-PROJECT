{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c533e468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at C:\\Users\\Acer\\AppData\\Local\\Temp\\matplotlib-hc8yibp1 because the default path (C:\\Users\\Acer\\.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76808e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fer2013.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a53a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for index, row in df.iterrows():\n",
    "    k = row['pixels'].split(\" \")\n",
    "    if row['Usage'] == 'Training':\n",
    "        X_train.append(np.array(k))\n",
    "        y_train.append(row['emotion'])\n",
    "    elif row['Usage'] == 'PublicTest':\n",
    "        X_test.append(np.array(k))\n",
    "        y_test.append(row['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c3bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['70', '80', '82', ..., '106', '109', '82'], dtype='<U3')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395b91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype = 'uint8')\n",
    "y_train = np.array(y_train, dtype = 'uint8')\n",
    "X_test = np.array(X_test, dtype = 'uint8')\n",
    "y_test = np.array(y_test, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993c5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "y_train= to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b02383",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce429de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "datagen = ImageDataGenerator( \n",
    "    rescale=1./255,\n",
    "    rotation_range = 10,\n",
    "    horizontal_flip = True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3ad4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.fit(X_train)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6a9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \n",
    "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a405627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b52ecd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FER_Model(input_shape=(48,48,1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    num_classes = 7\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
    "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
    "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    conv2_2 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
    "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
    "    conv3_3 = BatchNormalization()(conv3_3)\n",
    "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
    "    conv3_4 = BatchNormalization()(conv3_4)\n",
    "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
    "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
    "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
    "    conv4_3 = BatchNormalization()(conv4_3)\n",
    "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
    "    conv4_4 = BatchNormalization()(conv4_4)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
    "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
    "    \n",
    "    #the 5-th block\n",
    "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
    "    conv5_1 = BatchNormalization()(conv5_1)\n",
    "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
    "    conv5_2 = BatchNormalization()(conv5_2)\n",
    "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
    "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
    "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model \n",
    "    model = Model(inputs =visible, outputs = ouput)\n",
    "    # summary layers\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f89038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 48, 48, 64)        256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 48, 48, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 24, 24, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 24, 24, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 12, 12, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 6, 6, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 6, 6, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 6, 6, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 6, 6, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 3, 3, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 3, 3, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 3, 3, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13111367 (50.02 MB)\n",
      "Trainable params: 13103431 (49.99 MB)\n",
      "Non-trainable params: 7936 (31.00 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = FER_Model()\n",
    "optimizer_legacy = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_legacy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0e11f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\979276106.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "448/448 [==============================] - 762s 2s/step - loss: 2.1674 - accuracy: 0.2283 - val_loss: 2.3896 - val_accuracy: 0.1861\n",
      "Epoch 2/5\n",
      "448/448 [==============================] - 781s 2s/step - loss: 1.7628 - accuracy: 0.2703 - val_loss: 1.7213 - val_accuracy: 0.3001\n",
      "Epoch 3/5\n",
      "448/448 [==============================] - 9256s 21s/step - loss: 1.6535 - accuracy: 0.3405 - val_loss: 1.7612 - val_accuracy: 0.3224\n",
      "Epoch 4/5\n",
      "448/448 [==============================] - 566s 1s/step - loss: 1.4401 - accuracy: 0.4427 - val_loss: 1.3986 - val_accuracy: 0.4466\n",
      "Epoch 5/5\n",
      "448/448 [==============================] - 540s 1s/step - loss: 1.3177 - accuracy: 0.4971 - val_loss: 1.7666 - val_accuracy: 0.3553\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=1,  \n",
    "                    validation_data=test_flow, validation_steps=len(X_test) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28cba37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\516418746.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "448/448 [==============================] - 697s 2s/step - loss: 1.2471 - accuracy: 0.5280 - val_loss: 1.3400 - val_accuracy: 0.4815\n",
      "Epoch 2/15\n",
      "448/448 [==============================] - 846s 2s/step - loss: 1.2035 - accuracy: 0.5448 - val_loss: 1.2377 - val_accuracy: 0.5355\n",
      "Epoch 3/15\n",
      "448/448 [==============================] - 900s 2s/step - loss: 1.1746 - accuracy: 0.5571 - val_loss: 1.1803 - val_accuracy: 0.5561\n",
      "Epoch 4/15\n",
      "448/448 [==============================] - 902s 2s/step - loss: 1.1385 - accuracy: 0.5733 - val_loss: 1.1874 - val_accuracy: 0.5684\n",
      "Epoch 5/15\n",
      "448/448 [==============================] - 699s 2s/step - loss: 1.1224 - accuracy: 0.5781 - val_loss: 1.1386 - val_accuracy: 0.5731\n",
      "Epoch 6/15\n",
      "448/448 [==============================] - 525s 1s/step - loss: 1.0974 - accuracy: 0.5887 - val_loss: 1.1607 - val_accuracy: 0.5687\n",
      "Epoch 7/15\n",
      "448/448 [==============================] - 559s 1s/step - loss: 1.0843 - accuracy: 0.5927 - val_loss: 1.1570 - val_accuracy: 0.5773\n",
      "Epoch 8/15\n",
      "448/448 [==============================] - 556s 1s/step - loss: 1.0578 - accuracy: 0.6040 - val_loss: 1.2424 - val_accuracy: 0.5447\n",
      "Epoch 9/15\n",
      "448/448 [==============================] - 528s 1s/step - loss: 1.0513 - accuracy: 0.6043 - val_loss: 1.0649 - val_accuracy: 0.6043\n",
      "Epoch 10/15\n",
      "448/448 [==============================] - 511s 1s/step - loss: 1.0253 - accuracy: 0.6168 - val_loss: 1.0391 - val_accuracy: 0.6213\n",
      "Epoch 11/15\n",
      "448/448 [==============================] - 491s 1s/step - loss: 1.0066 - accuracy: 0.6237 - val_loss: 1.1056 - val_accuracy: 0.5982\n",
      "Epoch 12/15\n",
      "448/448 [==============================] - 547s 1s/step - loss: 0.9938 - accuracy: 0.6307 - val_loss: 1.0324 - val_accuracy: 0.6278\n",
      "Epoch 13/15\n",
      "448/448 [==============================] - 1023s 2s/step - loss: 0.9784 - accuracy: 0.6371 - val_loss: 1.0578 - val_accuracy: 0.6121\n",
      "Epoch 14/15\n",
      "448/448 [==============================] - 1013s 2s/step - loss: 0.9752 - accuracy: 0.6397 - val_loss: 1.0231 - val_accuracy: 0.6308\n",
      "Epoch 15/15\n",
      "448/448 [==============================] - 1013s 2s/step - loss: 0.9511 - accuracy: 0.6469 - val_loss: 1.0035 - val_accuracy: 0.6255\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=1,  \n",
    "                    validation_data=test_flow, validation_steps=len(X_test) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5febbc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\1440028572.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "448/448 [==============================] - 1024s 2s/step - loss: 0.9355 - accuracy: 0.6548 - val_loss: 1.0198 - val_accuracy: 0.6230\n",
      "Epoch 2/10\n",
      "448/448 [==============================] - 1017s 2s/step - loss: 0.9260 - accuracy: 0.6586 - val_loss: 0.9894 - val_accuracy: 0.6347\n",
      "Epoch 3/10\n",
      "448/448 [==============================] - 1015s 2s/step - loss: 0.9035 - accuracy: 0.6654 - val_loss: 1.0016 - val_accuracy: 0.6330\n",
      "Epoch 4/10\n",
      "448/448 [==============================] - 1035s 2s/step - loss: 0.8891 - accuracy: 0.6704 - val_loss: 1.0323 - val_accuracy: 0.6172\n",
      "Epoch 5/10\n",
      "448/448 [==============================] - 1025s 2s/step - loss: 0.8804 - accuracy: 0.6750 - val_loss: 0.9606 - val_accuracy: 0.6506\n",
      "Epoch 6/10\n",
      "448/448 [==============================] - 1023s 2s/step - loss: 0.8698 - accuracy: 0.6793 - val_loss: 1.0360 - val_accuracy: 0.6297\n",
      "Epoch 7/10\n",
      "448/448 [==============================] - 1026s 2s/step - loss: 0.8557 - accuracy: 0.6840 - val_loss: 1.0249 - val_accuracy: 0.6333\n",
      "Epoch 8/10\n",
      "448/448 [==============================] - 1016s 2s/step - loss: 0.8415 - accuracy: 0.6900 - val_loss: 0.9936 - val_accuracy: 0.6372\n",
      "Epoch 9/10\n",
      "448/448 [==============================] - 1005s 2s/step - loss: 0.8232 - accuracy: 0.6953 - val_loss: 0.9832 - val_accuracy: 0.6411\n",
      "Epoch 10/10\n",
      "220/448 [=============>................] - ETA: 8:21 - loss: 0.7963 - accuracy: 0.7061"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/model/conv5_2/Conv2D/Conv2DBackpropFilter defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\979276106.py\", line 2, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 598, in minimize\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 656, in _compute_gradients\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 532, in _get_gradients\n\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node gradient_tape/model/conv5_2/Conv2D/Conv2DBackpropFilter}}]] [Op:__inference_train_function_4454]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit_generator(train_flow, \n\u001b[0;32m      3\u001b[0m                     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m/\u001b[39m batch_size, \n\u001b[0;32m      4\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mnum_epochs,  \n\u001b[0;32m      5\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \n\u001b[0;32m      6\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_flow, validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_test) \u001b[38;5;241m/\u001b[39m batch_size)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   2914\u001b[0m     generator,\n\u001b[0;32m   2915\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   2916\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m   2917\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2918\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   2919\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[0;32m   2920\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m   2921\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[0;32m   2922\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[0;32m   2923\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[0;32m   2924\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m   2925\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[0;32m   2926\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   2927\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[0;32m   2928\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/model/conv5_2/Conv2D/Conv2DBackpropFilter defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\979276106.py\", line 2, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2913, in fit_generator\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 598, in minimize\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 656, in _compute_gradients\n\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\legacy\\optimizer_v2.py\", line 532, in _get_gradients\n\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node gradient_tape/model/conv5_2/Conv2D/Conv2DBackpropFilter}}]] [Op:__inference_train_function_4454]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=1,  \n",
    "                    validation_data=test_flow, validation_steps=len(X_test) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ef459d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_65816\\979276106.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_flow,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "448/448 [==============================] - 1013s 2s/step - loss: 0.8098 - accuracy: 0.7004 - val_loss: 1.0279 - val_accuracy: 0.6322\n",
      "Epoch 2/5\n",
      "448/448 [==============================] - 1013s 2s/step - loss: 0.7983 - accuracy: 0.7063 - val_loss: 0.9687 - val_accuracy: 0.6590\n",
      "Epoch 3/5\n",
      "448/448 [==============================] - 1023s 2s/step - loss: 0.7814 - accuracy: 0.7189 - val_loss: 1.0066 - val_accuracy: 0.6428\n",
      "Epoch 4/5\n",
      "448/448 [==============================] - 1035s 2s/step - loss: 0.7665 - accuracy: 0.7198 - val_loss: 0.9992 - val_accuracy: 0.6481\n",
      "Epoch 5/5\n",
      "448/448 [==============================] - 1051s 2s/step - loss: 0.7599 - accuracy: 0.7232 - val_loss: 1.0221 - val_accuracy: 0.6278\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit_generator(train_flow, \n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    epochs=num_epochs,  \n",
    "                    verbose=1,  \n",
    "                    validation_data=test_flow, validation_steps=len(X_test) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3eae150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1821be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model = model_from_json(open(\"model.json\", \"r\").read())\n",
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a34f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faf7471b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# cap=cv2.VideoCapture(0)\n",
    "# while cap.isOpened():\n",
    "#     res,frame=cap.read()\n",
    "#     height, width , channel = frame.shape\n",
    "#     gray_image= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "#     try:\n",
    "#         for (x,y, w, h) in faces:\n",
    "#             cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  2)\n",
    "#             roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
    "#             roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "#             image_pixels = img_to_array(roi_gray)\n",
    "#             image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
    "#             image_pixels /= 255\n",
    "            \n",
    "#             predictions = model.predict(image_pixels)\n",
    "#             max_index = np.argmax(predictions[0])\n",
    "#             emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "#             emotion_prediction = emotion_detection[max_index]\n",
    "            \n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "\n",
    "#     cv2.imshow('Emotion Detection', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "944d4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# # Assuming 'face_haar_cascade', 'model', and other necessary imports are defined earlier\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     res, frame = cap.read()\n",
    "#     height, width, channel = frame.shape\n",
    "\n",
    "#     # Creating an Overlay window to write prediction and confidence\n",
    "#     sub_img = frame[0:int(height/6), 0:int(width)]\n",
    "#     black_rect = np.ones(sub_img.shape, dtype=np.uint8) * 0\n",
    "#     res = cv2.addWeighted(sub_img, 0.77, black_rect, 0.23, 0)\n",
    "\n",
    "#     FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     FONT_SCALE = 0.8\n",
    "#     FONT_THICKNESS = 2\n",
    "#     lable_color = (10, 10, 255)\n",
    "#     lable = \"Emotions\"\n",
    "#     lable_dimension = cv2.getTextSize(lable, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "#     textX = int((res.shape[1] - lable_dimension[0]) / 2)\n",
    "#     textY = int((res.shape[0] + lable_dimension[1]) / 2)\n",
    "#     cv2.putText(res, lable, (textX, textY), FONT, FONT_SCALE, (0, 0, 0), FONT_THICKNESS)\n",
    "\n",
    "#     # Prediction part\n",
    "#     gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "#     try:\n",
    "#         for (x, y, w, h) in faces:\n",
    "#             cv2.rectangle(frame, pt1=(x, y), pt2=(x+w, y+h), color=(255, 0, 0), thickness=2)\n",
    "#             roi_gray = gray_image[y-5:y+h+5, x-5:x+w+5]\n",
    "#             roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "#             image_pixels = img_to_array(roi_gray)\n",
    "#             image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "#             image_pixels /= 255\n",
    "#             predictions = model.predict(image_pixels)\n",
    "#             max_index = np.argmax(predictions[0])\n",
    "#             emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "#             emotion_prediction = emotion_detection[max_index]\n",
    "#             cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0, textY+22+5), FONT, 0.7, lable_color, 2)\n",
    "#             #lable_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0])*100, 1)) + \"%\")\n",
    "#             violation_text_dimension = cv2.getTextSize(lable_violation, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "#             violation_x_axis = int(res.shape[1] - violation_text_dimension[0])\n",
    "#             cv2.putText(res, lable_violation, (violation_x_axis, textY+22+5), FONT, 0.7, lable_color, 2)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     frame[0:int(height/6), 0:int(width)] = res\n",
    "#     cv2.imshow('frame', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Assuming 'face_haar_cascade', 'model', and other necessary imports are defined earlier\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    res, frame = cap.read()\n",
    "    height, width, channel = frame.shape\n",
    "\n",
    "    # Create a transparent overlay with a completely transparent green rectangle\n",
    "    overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "    rect_start = (0, 0)\n",
    "    rect_end = (width, int(height/6))\n",
    "    cv2.rectangle(overlay, rect_start, rect_end, (0, 255, 0, 0), cv2.FILLED)\n",
    "\n",
    "    # Prediction part\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    \n",
    "    try:\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, pt1=(x, y), pt2=(x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "            roi_gray = gray_image[y-5:y+h+5, x-5:x+w+5]\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "            image_pixels = img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "            image_pixels /= 255\n",
    "            predictions = model.predict(image_pixels)\n",
    "            max_index = np.argmax(predictions[0])\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "\n",
    "            # Place the detected emotion with the moving face\n",
    "            text_size = cv2.getTextSize(emotion_prediction, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "            textX_emotion = int(x + (w - text_size[0]) / 2)\n",
    "            textY_emotion = int(y - 10)\n",
    "\n",
    "            cv2.putText(frame, f\"Detected Emotion: {emotion_prediction}\", (textX_emotion, textY_emotion), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Combine the frame and overlay\n",
    "    result = cv2.addWeighted(frame, 1, overlay, 0, 0)\n",
    "\n",
    "    cv2.imshow('frame', result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649c7e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 429ms/step\n",
      "Final Emotion: sad\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Assuming 'face_haar_cascade', 'model', and other necessary imports are defined earlier\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "emotion_results = []\n",
    "\n",
    "# Set the capture duration to 10 seconds\n",
    "capture_duration = 10  # in seconds\n",
    "start_time = cv2.getTickCount()\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()\n",
    "\n",
    "    if elapsed_time >= capture_duration:\n",
    "        break\n",
    "\n",
    "    res, frame = cap.read()\n",
    "    height, width, channel = frame.shape\n",
    "\n",
    "    # Create a transparent overlay with a completely transparent green rectangle\n",
    "    overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "    rect_start = (0, 0)\n",
    "    rect_end = (width, int(height/6))\n",
    "    cv2.rectangle(overlay, rect_start, rect_end, (0, 255, 0, 0), cv2.FILLED)\n",
    "\n",
    "    # Prediction part\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
    "    \n",
    "    try:\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, pt1=(x, y), pt2=(x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "            roi_gray = gray_image[y-5:y+h+5, x-5:x+w+5]\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "            image_pixels = img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "            image_pixels /= 255\n",
    "            predictions = model.predict(image_pixels)\n",
    "            max_index = np.argmax(predictions[0])\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "\n",
    "            # Store detected emotions in a list\n",
    "            emotion_results.append(emotion_prediction)\n",
    "\n",
    "            # Place the detected emotion with the moving face\n",
    "            text_size = cv2.getTextSize(emotion_prediction, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "            textX_emotion = int(x + (w - text_size[0]) / 2)\n",
    "            textY_emotion = int(y - 10)\n",
    "\n",
    "            cv2.putText(frame, f\"Detected Emotion: {emotion_prediction}\", (textX_emotion, textY_emotion), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Combine the frame and overlay\n",
    "    result = cv2.addWeighted(frame, 1, overlay, 0, 0)\n",
    "\n",
    "    cv2.imshow('frame', result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Determine the final output based on the majority emotion in the list\n",
    "final_emotion = max(set(emotion_results), key=emotion_results.count)\n",
    "print(f\"Final Emotion: {final_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb37419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
